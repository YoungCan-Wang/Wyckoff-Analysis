# -*- coding: utf-8 -*-
"""
é˜¶æ®µ 3ï¼šæ‰¹é‡ AI ç ”æŠ¥
æ‹‰å–é€‰ä¸­è‚¡ç¥¨çš„ OHLCV â†’ ç¬¬äº”æ­¥ç‰¹å¾å·¥ç¨‹ â†’ AI åˆ†æ â†’ é£ä¹¦å‘é€
"""
from __future__ import annotations

import os
import sys
from datetime import date, datetime, timedelta

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd

from integrations.ai_prompts import WYCKOFF_FUNNEL_SYSTEM_PROMPT
from integrations.fetch_a_share_csv import _resolve_trading_window, _fetch_hist
from integrations.llm_client import call_llm
from utils.feishu import send_feishu_notification
from core.wyckoff_engine import normalize_hist_from_fetch

TRADING_DAYS = 500
FEISHU_MAX_LEN = 12000
GEMINI_MODEL_FALLBACK = "gemini-2.0-flash-lite"
OPERATION_TARGET = 6

RECENT_DAYS = 15
HIGHLIGHT_DAYS = 60
HIGHLIGHT_PCT_THRESHOLD = 5.0
HIGHLIGHT_VOL_RATIO = 2.0
DEBUG_MODEL_IO = os.getenv("DEBUG_MODEL_IO", "").strip().lower() in {"1", "true", "yes", "on"}
DEBUG_MODEL_IO_FULL = os.getenv("DEBUG_MODEL_IO_FULL", "").strip().lower() in {"1", "true", "yes", "on"}


def _dump_model_input(
    items: list[dict],
    model: str,
    system_prompt: str,
    user_message: str,
) -> str:
    if not DEBUG_MODEL_IO:
        return ""

    logs_dir = os.getenv("LOGS_DIR", "logs")
    os.makedirs(logs_dir, exist_ok=True)
    path = os.path.join(logs_dir, f"step3_model_input_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")
    symbols_line = ", ".join(f"{x.get('code', '')}" for x in items)
    body = (
        f"[step3] model={model}\n"
        f"[step3] symbol_count={len(items)}\n"
        f"[step3] symbols={symbols_line}\n"
        f"[step3] system_prompt_len={len(system_prompt)}\n"
        f"[step3] user_message_len={len(user_message)}\n"
    )
    if DEBUG_MODEL_IO_FULL:
        body += (
            "\n===== SYSTEM PROMPT =====\n"
            f"{system_prompt}\n"
            "\n===== USER MESSAGE =====\n"
            f"{user_message}\n"
        )
    with open(path, "w", encoding="utf-8") as f:
        f.write(body)
    print(f"[step3] æ¨¡å‹è¾“å…¥å·²è½ç›˜: {path}")
    return path


def _compress_report(report: str, max_len: int = FEISHU_MAX_LEN) -> str:
    if len(report) <= max_len:
        return report
    truncated = report[:max_len]
    last_period = truncated.rfind("ã€‚")
    if last_period > max_len // 2:
        return truncated[: last_period + 1]
    return truncated + "â€¦"


def generate_stock_payload(
    stock_code: str,
    stock_name: str,
    wyckoff_tag: str,
    df: pd.DataFrame,
) -> str:
    """
    ç¬¬äº”æ­¥ï¼šå°† 500 å¤© OHLCV æµ“ç¼©ä¸ºå‘ç»™ AI çš„é«˜å¯†åº¦æ–‡æœ¬ã€‚
    1. å¤§èƒŒæ™¯ï¼ˆMA50 / MA200 / ä¹–ç¦»ç‡ï¼‰
    2. è¿‘ 15 æ—¥é‡ä»·åˆ‡ç‰‡ï¼ˆæ”¾é‡æ¯” + æ¶¨è·Œå¹…ï¼‰
    3. è¿‘ 60 æ—¥å¼‚åŠ¨é«˜å…‰æ—¶åˆ»
    """
    df = df.copy().sort_values("date").reset_index(drop=True)
    close = df["close"].astype(float)
    volume = df["volume"].astype(float)
    df["ma50"] = close.rolling(50).mean()
    df["ma200"] = close.rolling(200).mean()
    df["vol_ma20"] = volume.rolling(20).mean()
    df["pct_chg_calc"] = close.pct_change() * 100

    latest = df.iloc[-1]
    ma50_val = latest["ma50"]
    ma200_val = latest["ma200"]
    close_val = latest["close"]

    if pd.notna(ma50_val) and pd.notna(ma200_val) and ma200_val > 0:
        if ma50_val > ma200_val:
            trend = "é•¿æœŸå¤šå¤´æ’åˆ— (MA50 > MA200)"
        else:
            trend = "é•¿æœŸç©ºå¤´æˆ–éœ‡è¡ (MA50 <= MA200)"
        bias_200 = (close_val - ma200_val) / ma200_val * 100
        background = (
            f"  [ç»“æ„èƒŒæ™¯] ç°ä»·:{close_val:.2f}, MA50:{ma50_val:.2f}, MA200:{ma200_val:.2f}ã€‚"
            f"{trend}ï¼Œå¹´çº¿ä¹–ç¦»ç‡:{bias_200:.1f}%"
        )
    else:
        background = f"  [ç»“æ„èƒŒæ™¯] ç°ä»·:{close_val:.2f}ï¼ˆæ•°æ®ä¸è¶³ä»¥è®¡ç®— MA200ï¼‰"

    header = (
        f"â€¢ {stock_code} {stock_name} | æœºå™¨æ ‡ç­¾ï¼š{wyckoff_tag}\n"
        f"  [ä»·æ ¼é”šç‚¹] æœ€æ–°å®é™…æ”¶ç›˜ä»·={close_val:.2f}ï¼ˆæ‰§è¡Œå»ºè®®éœ€å›´ç»•è¯¥é”šç‚¹ç»™å‡ºç»“æ„æˆ˜åŒºï¼Œä¸å¾—ç»™å•ç‚¹é¢„æµ‹ä»·ï¼‰ã€‚\n"
        f"{background}\n"
    )

    # è¿‘ 15 æ—¥é‡ä»·åˆ‡ç‰‡
    recent = df.tail(RECENT_DAYS)
    recent_lines = ["  [è¿‘15æ—¥é‡ä»·åˆ‡ç‰‡]:"]
    for _, row in recent.iterrows():
        vol_ratio = row["volume"] / row["vol_ma20"] if pd.notna(row["vol_ma20"]) and row["vol_ma20"] > 0 else 0
        pct = row["pct_chg_calc"] if pd.notna(row["pct_chg_calc"]) else 0
        date_str = str(row["date"])[5:10]
        recent_lines.append(f"    {date_str}: æ”¶{row['close']:.2f} ({pct:+.1f}%), é‡æ¯”:{vol_ratio:.1f}x")

    # è¿‘ 60 æ—¥å¼‚åŠ¨é«˜å…‰
    tail60 = df.tail(HIGHLIGHT_DAYS)
    highlights = []
    for _, row in tail60.iterrows():
        pct = row["pct_chg_calc"] if pd.notna(row["pct_chg_calc"]) else 0
        vol_ratio = row["volume"] / row["vol_ma20"] if pd.notna(row["vol_ma20"]) and row["vol_ma20"] > 0 else 0
        if abs(pct) >= HIGHLIGHT_PCT_THRESHOLD or vol_ratio >= HIGHLIGHT_VOL_RATIO:
            date_str = str(row["date"])[5:10]
            tag_parts = []
            if abs(pct) >= HIGHLIGHT_PCT_THRESHOLD:
                tag_parts.append(f"æ¶¨è·Œ{pct:+.1f}%")
            if vol_ratio >= HIGHLIGHT_VOL_RATIO:
                tag_parts.append(f"é‡æ¯”{vol_ratio:.1f}x")
            highlights.append(f"    {date_str}: æ”¶{row['close']:.2f} ({', '.join(tag_parts)})")

    highlight_section = ""
    if highlights:
        highlight_section = "\n  [è¿‘60æ—¥å¼‚åŠ¨é«˜å…‰]:\n" + "\n".join(highlights) + "\n"

    return header + "\n".join(recent_lines) + "\n" + highlight_section + "\n"


def run(
    symbols_info: list[dict] | list[str],
    webhook_url: str,
    api_key: str,
    model: str,
    benchmark_context: dict | None = None,
) -> tuple[bool, str, str]:
    """
    æ‹‰å– OHLCV â†’ ç¬¬äº”æ­¥ç‰¹å¾å·¥ç¨‹ â†’ AI ç ”æŠ¥ â†’ é£ä¹¦å‘é€ã€‚
    symbols_info: list[{"code", "name", "tag"}] æˆ– list[str]ï¼ˆå‘åå…¼å®¹ï¼‰ã€‚
    """
    if not symbols_info:
        print("[step3] æ— è¾“å…¥è‚¡ç¥¨ï¼Œè·³è¿‡")
        return (True, "skipped_no_symbols", "")

    # å…¼å®¹æ—§è°ƒç”¨ï¼ˆçº¯ str åˆ—è¡¨ï¼‰
    items: list[dict] = []
    for s in symbols_info:
        if isinstance(s, str):
            items.append({"code": s, "name": s, "tag": ""})
        else:
            items.append(s)

    print(f"[step3] AI è¾“å…¥è‚¡ç¥¨æ•°={len(items)}ï¼ˆå…¨é‡å‘½ä¸­è¾“å…¥ï¼‰")

    end_day = date.today() - timedelta(days=1)
    window = _resolve_trading_window(end_calendar_day=end_day, trading_days=TRADING_DAYS)

    parts: list[str] = []
    failed: list[tuple[str, str]] = []
    for item in items:
        code = item["code"]
        name = item.get("name", code)
        tag = item.get("tag", "")
        try:
            df_raw = _fetch_hist(code, window, "qfq")
            df = normalize_hist_from_fetch(df_raw)
            payload = generate_stock_payload(code, name, tag, df)
            parts.append(payload)
        except Exception as e:
            failed.append((code, str(e)))

    if not parts:
        if failed:
            detail = ", ".join(f"{s}({e})" for s, e in failed)
            print(f"[step3] OHLCV å…¨éƒ¨æ‹‰å–å¤±è´¥: {detail}")
            return (False, "data_all_failed", "")
        return (True, "no_data_but_no_error", "")

    benchmark_lines = []
    if benchmark_context:
        benchmark_lines.append("[å®è§‚æ°´æ¸© / Benchmark Context]")
        benchmark_lines.append(
            f"regime={benchmark_context.get('regime')}, "
            f"close={benchmark_context.get('close')}, "
            f"ma50={benchmark_context.get('ma50')}, "
            f"ma200={benchmark_context.get('ma200')}, "
            f"ma50_slope_5d={benchmark_context.get('ma50_slope_5d')}"
        )
        benchmark_lines.append(
            f"recent3_pct={benchmark_context.get('recent3_pct')}, "
            f"recent3_cum_pct={benchmark_context.get('recent3_cum_pct')}, "
            f"tuned={benchmark_context.get('tuned')}"
        )

    user_message = (
        ("{}\n\n".format("\n".join(benchmark_lines)) if benchmark_lines else "")
        + "ä»¥ä¸‹æ˜¯é€šè¿‡ Wyckoff Funnel å‘½ä¸­çš„å…¨é‡å€™é€‰åå•ã€‚\n"
        + "è¯·å…ˆä»å…¨éƒ¨è¾“å…¥ä¸­ç­›å‡ºâ€œå€¼å¾—åŠ å…¥è‡ªé€‰è§‚å¯Ÿæ± â€çš„æ ‡çš„ï¼ˆæ•°é‡ä¸é™ï¼‰ï¼Œå¹¶æ˜ç¡®æ¯åªçš„è§‚å¯Ÿæ¡ä»¶ï¼›"
        + f"å†ä»è§‚å¯Ÿæ± ä¸­ä¸¥æ ¼æŒ‘é€‰â€œæ¬¡æ—¥å¯ä¹°å…¥çš„æ“ä½œæ± â€{OPERATION_TARGET}åªã€‚\n"
        + f"è¾“å‡ºå¿…é¡»åŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼š1) è§‚å¯Ÿæ± ï¼ˆä¸é™ï¼Œå«è§‚å¯Ÿæ¡ä»¶ï¼‰ 2) æ“ä½œæ± ï¼ˆå›ºå®š{OPERATION_TARGET}åªï¼‰ã€‚\n"
        + "ç¡¬çº¦æŸï¼šæ“ä½œæ± å¿…é¡»æ˜¯è§‚å¯Ÿæ± å­é›†ï¼Œä¸”ä¸¤éƒ¨åˆ†åªèƒ½ä½¿ç”¨è¾“å…¥åˆ—è¡¨ä¸­çš„è‚¡ç¥¨ä»£ç ã€‚\n\n"
        + "äº¤æ˜“æ‰§è¡Œç¡¬çº¦æŸï¼š\n"
        + "1) ç¦æ­¢å•ç‚¹ä»·æ ¼æŒ‡ä»¤ï¼Œå¿…é¡»ç»™â€œç»“æ„æˆ˜åŒº(Action Zone) + ç›˜é¢ç¡®è®¤æ¡ä»¶(Tape Condition)â€ã€‚\n"
        + "2) æˆ˜åŒºéœ€å›´ç»•æ¯åªè‚¡ç¥¨çš„â€œä»·æ ¼é”šç‚¹ï¼ˆæœ€æ–°æ”¶ç›˜ä»·ï¼‰â€æè¿°ï¼Œä½†ä¸å¾—åˆ»èˆŸæ±‚å‰‘ã€‚\n"
        + "3) ä¹°å…¥è§¦å‘å¿…é¡»åŒ…å«é‡ä»·ç¡®è®¤æ¡ä»¶ï¼ˆå¦‚ç¼©é‡å›è¸©/æ‹’ç»ä¸‹ç ´ï¼‰ï¼›è‹¥æ”¾é‡ä¸‹ç ´ï¼Œå¿…é¡»å–æ¶ˆä¹°å…¥ã€‚\n"
        + "4) å¼ºåŠ¿çªç ´æ ‡çš„å¿…é¡»ç»™â€œé˜²è¸ç©ºç­–ç•¥â€ï¼šå¼€ç›˜å¼ºåŠ¿ç¡®è®¤åå¯å…ˆç”¨è®¡åˆ’ä»“ä½1/3è¯•å•ï¼Œå…¶ä½™ç­‰å¾…äºŒæ¬¡ç¡®è®¤ã€‚\n\n"
        + "\n".join(parts)
    )
    _dump_model_input(items=items, model=model, system_prompt=WYCKOFF_FUNNEL_SYSTEM_PROMPT, user_message=user_message)

    report = ""
    models_to_try = [model]
    if GEMINI_MODEL_FALLBACK and GEMINI_MODEL_FALLBACK != model:
        models_to_try.append(GEMINI_MODEL_FALLBACK)

    for m in models_to_try:
        try:
            report = call_llm(
                provider="gemini",
                model=m,
                api_key=api_key,
                system_prompt=WYCKOFF_FUNNEL_SYSTEM_PROMPT,
                user_message=user_message,
                timeout=300,
            )
            break
        except Exception as e:
            print(f"[step3] æ¨¡å‹ {m} å¤±è´¥: {e}")
            if m == models_to_try[-1]:
                return (False, "llm_failed", "")

    content = _compress_report(report)
    if failed:
        content += f"\n\n**è·å–å¤±è´¥**: {', '.join(f'{s}({e})' for s, e in failed)}"

    title = f"ğŸ“„ æ‰¹é‡ç ”æŠ¥ {date.today().strftime('%Y-%m-%d')}"
    sent = send_feishu_notification(webhook_url, title, content)
    if not sent:
        print("[step3] é£ä¹¦æ¨é€å¤±è´¥")
        return (False, "feishu_failed", report)
    print(f"[step3] ç ”æŠ¥å‘é€æˆåŠŸï¼Œè‚¡ç¥¨æ•°={len(items)}ï¼Œæ‹‰å–å¤±è´¥æ•°={len(failed)}")
    return (True, "ok", report)
